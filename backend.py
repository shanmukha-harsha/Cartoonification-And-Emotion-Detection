# -*- coding: utf-8 -*-
"""backend.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RfkGZIPfWfJnwMC7rljH-FbhgLymqwka
"""

from flask import Flask, render_template, request, json
from werkzeug.utils import secure_filename
import requests
import cv2 #for image processing
import numpy as np #to store image
import sys
import matplotlib . pyplot as plt
import os
import random
import numpy as np
from keras.models import model_from_j son
from keras.preprocessing import image
app = Flas k(_ name_)
#gpath= ' '
#em1=' '
def save(imagex, ImagePath):
  newName="cartoonified_Image_1"
  path1 = os.path.dirname(ImagePath)
  extension=os.path.splitext(ImagePath)[1]
  path= os.path.join(path1, newName+extension)
  #gpath=path
  cv2.imwrite(path, imagex)
  em1=c_emotion(path)
  # print(em1 )
  return path , em1

def cartoonify(ImagePath,filter):
  originalmage = cv2.imread(ImagePath)
  originalmage = cv2.cvtcolor(originalmage, cv2 .COLOR_BGR2RGB)
  w,h,o=originalmage.shape
  if originalmage is None:
    print("Can not find any image. Choose appropriate file")
    sys.exit()
  ReSizedl = cv2.resize(originalmage, (h,w))
  grayscaleimage= cv2.cvtcolor(originalmage, cv2 .COLOR_BGR2GRAY)
  ReSized2 = cv2.resize(grayscaleimage, (h,w))
  smoothGrayScale = cv2.medianBlur (grayScaleimage, 5)
  ReSized3 = cv2.resize(smoothGrayScale, (h,w))
  getEdge = cv2.adaptiveThreshold(smoothGrayscale, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 9)
  ReSized4 = cv2.resize(getEdge, (h,w))
  colorimage = cv2.bilatera1Filter(originalmage, 9, 300, 300)
  Resized5 = cv2.resize(colorrmage, (h,w))
  cartoonimage = cv2.bitwise_and(colorimage, colorimage, mask=getEdge)
  ReSized6 = cv2.resize(cartoonimage, (h,w))
  images=[ReSizedl, ReSized2, ReSized3, ReSized4, ReSized5, ReSized6]
  fig, axes= plt.subplots(l,2,figsize=(8,8), subplot_kw={'xticks' :[], 'yticks' :[]},
  gridspec_kw=dict(hspace=0.1, wspace=0.1))
  for i, ax in enumerate(axes .flat):
    if(i==0) :
      ax.imshow(images[i], cmap='gray')
    else:
      ax.imshow(images[filter], cmap='gray')
  name,eml=save(images[filter],ImagePath)
  return name,eml

def emotion(ImagePath) :
  model= model_from_json(open( 'model.json' , "r").read())
  #load weights
  model.load_weights('model.h5')
  face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml ')
  test_img = cv2.imread(ImagePath)
  gray_img = cv2.cvtColor (test_img, cv2.COLOR_BGR2GRAY)
  faces_detected = face_haar_cascade.detectMultiScale(gray_img,1. 32, 5)
  img_pixels = [0]
  for (x,y,w,h) in faces_detected:
    cv2.rectangle(test_img, (x ,y) , (x+w,y+h) , (255 ,0,0) ,thickness=7)
    roi_gray = gray_img[y:y+w,x:x+h]
    roi_gray = cv2.resize(roi_gray , (48,48))
    img_pixels = image.img_to_array(roi_gray)
    img_pixels = np.expand_dims(img_pixels, axis= 0)
    img_pixels /= 255
    # print(img_pixels)
  if(img_pixels.any()==0):
    return "Not Found"
  a=random.randint(0,2)
  predictions= model.predict(img_pixels)
  max_index = np.argmax(predictions[0] )
  angry=( 'You look angry and frustrated . Please calm down', 'Angry 2' )
  disgust=( 'capl' , 'cap2' )
  fear=( ' capl ' , 'cap2' )
  happy=( 'capl' , 'cap2' )
  sad=( 'capl' , ' cap2' )
  surprise=( 'capl' , 'cap2' )
  neutral=('capl' , 'cap2' )
  # emotions= (angry, di sgust, fear, happy, sad, surprise, neutral)
  emotions= ( ' You look angry and frust rated. Please calm down ' ,
  'A look of di sgust . Seems l ike you need to go to your happy place .' ,
  ' You look fright ened. Everythi ng is goi ng to be okay ' ,
  ' You look so happy . Keep going have a good day .' ,
  ' You look sad . Cheer up and watch a movie ' ,
  ' Looks like someone has got a big surprise ' ,
  ' You seem pretty calm without any emotions right now.' )
  predicted_emotion = emotions[max_index]
  # predicted_emotion=predict[a]
  return predicted_emotion

def c_emotion(ImagePath) :
  model = model_from_json(open('model.json',"r") ,read())
  #load weights
  model .load_weights('model .h5')
  face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default .xml ')
  test_img=cv2. imread(ImagePath)
  gray_img= cv2.cvtcolor(test_img, cv2.COLOR_BGR2GRAY)
  faces_detected = face_haar_cascade.detectMultiScale(gray_img,1 .32, 5)
  img_pixels=[0]
  for (x,y,w,h) in faces_detected:
    cv2 .rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)
    roi_gray=gray_img[y:y+w,x :x+h]
    roi_gray=cv2.resize(roi_gray, (48 ,48))
    img_pixels = image .img_to_array( roi_gray)
    img_pixels = np .expand_dims(img_pixels, axis= 0)
    img_pixels /= 255
  # print (img_pixels)
  if (img_pixels .any() ==0):
    return "Not Found"
  a=random.randint(0,2)
  predictions = model.predict(img_pixels)
  max_index = np.argmax(predictions[0])
  # emotions= (angry, disgust, fear, happy, sad, surprise, neutral)
  emotions = ('<p id= "emtn">You look angry and frustrated. Please calm down<br><br>Quite an angry look. Peace out<br>The HULK look</p>',
  '<p id="emt n">A look of disgust. seems like you need to go to your happy place .<br><br>My face when you make bad jokes<br> Eww1\J1.\J1.\J1.\J1.,ww! </p>' ,
  '<p id= "emtn">You look fr ightened. Everything is going to be okay<br><br>The time I saw Conjuring alone<br>Fear of growing up</p>',
  '<p id="emt n">You look so happy. Keep going have a good day.<br><br>When the weekend arrives<br>Just smile away your problems</ p>',
  '<p id="emtn">You look sad. Cheer up and watch a movie<br><br>Frown like a clown<br>Tears are words t hat need to be written</p>',
  '<p id="emt n">Looks like someone has got a big surprise<br><br>When I see an empty box on the street<br>The Michael Scott look</p>",
  '<p id="emtn">You seem pretty calm without any emotions right now .<br><br>Calm before the storm<br>Peace out like BUDDHA</p>')
  predicted_emotion = emotions[max_index]
  #predicted_emotion=predict[a]
  return predicted_emotion

@app.route("/", methods= ["GET", "POST" ])
def new() :
  if request.method== "POST":
    f = request.files['fileupload' ]
    f.save(secure_filename(f.filename))
    filter=int(request.values.get("filter" ))
    ImagePath=" ./"+str(f.filename)
    nam,eml=cartoonify(ImagePath,filter)
    em=emotion(ImagePath)
    #eml=emotion(gpath)
    di =dict()
    di[0]=nam
    di[l]=em
    di[2]=em1
    di[3]=ImagePath
    print(di)
    return di
  return render_template("index.html" )

@app.after_request
def after_request(response) :
  header = response.headers
  header['Access-control-Allow-origin'] = '*'
  header[ 'Access-Control-Allow-Headers' ] = 'Content-Type, Authorization'
  header[ 'Access-Control-Allow-Methods' ] = 'OPTIONS, HEAD, GET, POST, DELETE, PUT'
  return response
if __name__ == "__main__":
  app.run(debug=True)